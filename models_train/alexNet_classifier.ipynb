{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"alexNet_classifier.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1sU4hIhlK1DarY0PqmHY2LrARLwOzYKYT","authorship_tag":"ABX9TyMHkRYIY4+8sdORHIkwb0dt"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BIH43sO6HYj2"},"source":["# Import packages"]},{"cell_type":"code","metadata":{"id":"dI5SqIi-40cv"},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","from keras.models import Sequential, load_model\n","# from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, Flatten\n","from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dense, Flatten, Dropout\n","\n","\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import os\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Utility function"],"metadata":{"id":"myGiQIO7_GN2"}},{"cell_type":"code","metadata":{"id":"Lb2r7v-RWxgv"},"source":["def uncompressArray(file_dir):\n","  uncompressed_data = []\n","  with open(file_dir, 'rb') as f:\n","    loaded_file = np.load(f)\n","    ks = list(loaded_file.keys())\n","    print(\"First, check the data!\")\n","    print(f\"Keys: {ks}\")\n","    ans = input(\"Please enter 'y' if you want to proceed: \")\n","    if ans == 'y':\n","      print(\"\\nloading data !\")\n","      for k in ks:\n","        uncompressed_data.append(loaded_file[k].copy())\n","        print(f\"load: {k}\")\n","    else:\n","      print(\"data is not loaded!\")\n","  return uncompressed_data\n","\n","def reshape_data(X):\n","  X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n","  return X"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UU47i2OwHURp"},"source":["# Data preprocessing"]},{"cell_type":"markdown","metadata":{"id":"uOVGojReJTl1"},"source":["## Import data"]},{"cell_type":"code","metadata":{"id":"LrbM1igDHsLK","executionInfo":{"status":"ok","timestamp":1659370508234,"user_tz":-120,"elapsed":5716,"user":{"displayName":"Modafar Al-Shouha","userId":"08841682443665180805"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b13f8cf0-20f2-4613-f1cd-ecfeabbd03d3"},"source":["data_file = '/content/drive/MyDrive/PhD/Szeged22_paper/Atca_Cyber_long_paper/data/arabic_data.npz'\n","\n","X_clean_train, X_clean_test, Y_clean_train, Y_clean_test = uncompressArray(data_file)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First, check the data!\n","Keys: ['X_train_arab', 'X_test_arab', 'Y_train_arab', 'Y_test_arab']\n","Please enter 'y' if you want to proceed: y\n","\n","loading data !\n","load: X_train_arab\n","load: X_test_arab\n","load: Y_train_arab\n","load: Y_test_arab\n"]}]},{"cell_type":"code","source":["print(X_clean_train.shape, X_clean_test.shape, Y_clean_train.shape, Y_clean_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVVTm_81SR1p","executionInfo":{"status":"ok","timestamp":1659370508235,"user_tz":-120,"elapsed":24,"user":{"displayName":"Modafar Al-Shouha","userId":"08841682443665180805"}},"outputId":"a1f79ce9-8a5f-4390-bdb1-2784877b0fd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(40320, 28, 28, 1) (10080, 28, 28, 1) (40320,) (10080,)\n"]}]},{"cell_type":"markdown","source":["## Split train and test"],"metadata":{"id":"zfPXruLtTAWk"}},{"cell_type":"code","source":["X_train, X_valid, Y_train, Y_valid = train_test_split(X_clean_train, Y_clean_train, test_size=0.2, random_state=42)\n","X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvdeyxnMS_tl","executionInfo":{"status":"ok","timestamp":1659370508235,"user_tz":-120,"elapsed":14,"user":{"displayName":"Modafar Al-Shouha","userId":"08841682443665180805"}},"outputId":"5804542c-3dc6-4e95-e6dc-8b0374effc4e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((32256, 28, 28, 1), (32256,), (8064, 28, 28, 1), (8064,))"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["X_test = X_clean_test.copy()"],"metadata":{"id":"kBD06S6XYf5M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ll7MAp69ug5V"},"source":["## Normalize data"]},{"cell_type":"code","metadata":{"id":"w_P4xE4Mug5V"},"source":["# # extract only one channel\n","# X_train = X_train[:,:,:,0]/255.\n","# X_valid = X_valid[:,:,:,0]/255.\n","# X_test = X_clean_test[:,:,:,0]/255.\n","\n","# X_train.shape, X_valid.shape, X_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C7Q_330Tu_Ve"},"source":["## Reshape data"]},{"cell_type":"code","metadata":{"id":"0gn2vHEHvOxV"},"source":["# X_train = reshape_data(X_train)\n","# X_valid = reshape_data(X_valid)\n","# X_test = reshape_data(X_test)\n","\n","# X_train.shape, X_valid.shape, X_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Z3DoC-e9j3K"},"source":["## One hot encoding"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cA7SZIOZS7Si","executionInfo":{"status":"ok","timestamp":1659370508815,"user_tz":-120,"elapsed":6,"user":{"displayName":"Modafar Al-Shouha","userId":"08841682443665180805"}},"outputId":"32289b38-63d5-48ed-b4a5-4efbb04e67b3"},"source":["# letters labels start from 11\n","Y_train = to_categorical(Y_train, dtype =\"uint8\")\n","Y_valid = to_categorical(Y_valid, dtype =\"uint8\")\n","Y_test = to_categorical(Y_clean_test, dtype =\"uint8\")\n","Y_train.shape, Y_valid.shape, Y_test.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((32256, 28), (8064, 28), (10080, 28))"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"LcTedgRFLcKu"},"source":["# Basic Model"]},{"cell_type":"code","source":["# https://analyticsindiamag.com/hands-on-guide-to-implementing-alexnet-with-keras-for-multi-class-image-classification/\n","\n","def AlexNet(input_shape=(28,28,1), no_classes=10):\n","\n","  model = Sequential()\n","\n","  #1st Convolutional Layer\n","  model.add(Conv2D(filters=96, input_shape=input_shape, kernel_size=(11,11), strides=(4,4), padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","  model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n","\n","  #2nd Convolutional Layer\n","  model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","  model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n","\n","  #3rd Convolutional Layer\n","  model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","\n","  #4th Convolutional Layer\n","  model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","\n","  #5th Convolutional Layer\n","  model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","  model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n","\n","  #Passing it to a Fully Connected layer\n","  model.add(Flatten())\n","  # 1st Fully Connected Layer\n","  model.add(Dense(4096, input_shape=input_shape))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","  # Add Dropout to prevent overfitting\n","  model.add(Dropout(0.4))\n","\n","  #2nd Fully Connected Layer\n","  model.add(Dense(4096))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","  #Add Dropout\n","  model.add(Dropout(0.4))\n","\n","  #3rd Fully Connected Layer\n","  model.add(Dense(1000))\n","  model.add(BatchNormalization())\n","  model.add(Activation('relu'))\n","  #Add Dropout\n","  model.add(Dropout(0.4))\n","\n","  #Output Layer\n","  model.add(Dense(no_classes))\n","  model.add(BatchNormalization())\n","  model.add(Activation('softmax'))\n","\n","  #Model Summary\n","  model.summary()\n","\n","  return model"],"metadata":{"id":"8WZnrrlUR4OV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OcExHlpg117c"},"source":["# Model training"]},{"cell_type":"code","source":["# Implement callback function to stop training\n","# when accuracy reaches e.g. ACCURACY_THRESHOLD = 0.85\n","\n","ACCURACY_THRESHOLD = 0.85\n","\n","class myCallback(tf.keras.callbacks.Callback): \n","  def __init__(self, test_data):\n","    self.test_data = test_data\n","\n","  def on_epoch_end(self, epoch, logs={}): \n","    x, y = self.test_data\n","    acc = self.model.evaluate(x, y, verbose=0)[1]\n","    print('\\nTesting acc: {}\\n'.format(acc))\n","    if acc > ACCURACY_THRESHOLD:\n","      print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))\n","      self.model.stop_training = True"],"metadata":{"id":"JY0DQODcdLZ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model configuration\n","batch_size = 32\n","img_width, img_height, img_num_channels = X_train.shape[1:]\n","loss_function = 'categorical_crossentropy'\n","no_epochs = 100\n","optimizer = 'adam'\n","verbosity = 1\n","num_folds = 5\n","no_classes = Y_train.shape[1]\n","\n","callbacks=myCallback((X_test, Y_test))\n","\n","# Determine shape of the data\n","input_shape = (img_width, img_height, img_num_channels)\n","\n","# Create model\n","model = AlexNet(input_shape, no_classes)\n","\n","# Compile model\n","model.compile(loss=loss_function,\n","              optimizer=optimizer,\n","              metrics=['accuracy', tf.keras.metrics.AUC(name='auc', multi_label=True)])\n","\n","# Fit model\n","history = model.fit(X_train, Y_train, ###Moda:XXX\n","                    batch_size=batch_size,\n","                    epochs=no_epochs,\n","                    verbose=verbosity,\n","                    validation_data=(X_valid, Y_valid),\n","                    callbacks=[callbacks])\n","\n","results = model.evaluate(X_test, Y_test, verbose=0)\n","\n","model.save('/content/drive/MyDrive/PhD/Szeged22_paper/Atca_Cyber_long_paper/saved_models/alexNet_classifier.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2ni_eMPoFAB","executionInfo":{"status":"ok","timestamp":1659209802358,"user_tz":-120,"elapsed":1757383,"user":{"displayName":"Modafar Al-Shouha","userId":"08841682443665180805"}},"outputId":"ee65e21a-2478-48ee-c0ce-831ca7747885"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_10 (Conv2D)          (None, 7, 7, 96)          11712     \n","                                                                 \n"," batch_normalization_18 (Bat  (None, 7, 7, 96)         384       \n"," chNormalization)                                                \n","                                                                 \n"," activation_18 (Activation)  (None, 7, 7, 96)          0         \n","                                                                 \n"," max_pooling2d_6 (MaxPooling  (None, 4, 4, 96)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 4, 4, 256)         614656    \n","                                                                 \n"," batch_normalization_19 (Bat  (None, 4, 4, 256)        1024      \n"," chNormalization)                                                \n","                                                                 \n"," activation_19 (Activation)  (None, 4, 4, 256)         0         \n","                                                                 \n"," max_pooling2d_7 (MaxPooling  (None, 2, 2, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 2, 2, 384)         885120    \n","                                                                 \n"," batch_normalization_20 (Bat  (None, 2, 2, 384)        1536      \n"," chNormalization)                                                \n","                                                                 \n"," activation_20 (Activation)  (None, 2, 2, 384)         0         \n","                                                                 \n"," conv2d_13 (Conv2D)          (None, 2, 2, 384)         1327488   \n","                                                                 \n"," batch_normalization_21 (Bat  (None, 2, 2, 384)        1536      \n"," chNormalization)                                                \n","                                                                 \n"," activation_21 (Activation)  (None, 2, 2, 384)         0         \n","                                                                 \n"," conv2d_14 (Conv2D)          (None, 2, 2, 256)         884992    \n","                                                                 \n"," batch_normalization_22 (Bat  (None, 2, 2, 256)        1024      \n"," chNormalization)                                                \n","                                                                 \n"," activation_22 (Activation)  (None, 2, 2, 256)         0         \n","                                                                 \n"," max_pooling2d_8 (MaxPooling  (None, 1, 1, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_2 (Flatten)         (None, 256)               0         \n","                                                                 \n"," dense_8 (Dense)             (None, 4096)              1052672   \n","                                                                 \n"," batch_normalization_23 (Bat  (None, 4096)             16384     \n"," chNormalization)                                                \n","                                                                 \n"," activation_23 (Activation)  (None, 4096)              0         \n","                                                                 \n"," dropout_6 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," dense_9 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," batch_normalization_24 (Bat  (None, 4096)             16384     \n"," chNormalization)                                                \n","                                                                 \n"," activation_24 (Activation)  (None, 4096)              0         \n","                                                                 \n"," dropout_7 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," dense_10 (Dense)            (None, 1000)              4097000   \n","                                                                 \n"," batch_normalization_25 (Bat  (None, 1000)             4000      \n"," chNormalization)                                                \n","                                                                 \n"," activation_25 (Activation)  (None, 1000)              0         \n","                                                                 \n"," dropout_8 (Dropout)         (None, 1000)              0         \n","                                                                 \n"," dense_11 (Dense)            (None, 28)                28028     \n","                                                                 \n"," batch_normalization_26 (Bat  (None, 28)               112       \n"," chNormalization)                                                \n","                                                                 \n"," activation_26 (Activation)  (None, 28)                0         \n","                                                                 \n","=================================================================\n","Total params: 25,725,364\n","Trainable params: 25,704,172\n","Non-trainable params: 21,192\n","_________________________________________________________________\n","Epoch 1/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 2.0728 - accuracy: 0.3579 - auc: 0.9062\n","Testing acc: 0.42599207162857056\n","\n","1008/1008 [==============================] - 20s 19ms/step - loss: 2.0717 - accuracy: 0.3583 - auc: 0.9064 - val_loss: 1.8878 - val_accuracy: 0.4103 - val_auc: 0.9322\n","Epoch 2/100\n","1008/1008 [==============================] - ETA: 0s - loss: 1.4536 - accuracy: 0.5499 - auc: 0.9572\n","Testing acc: 0.49166667461395264\n","\n","1008/1008 [==============================] - 17s 16ms/step - loss: 1.4536 - accuracy: 0.5499 - auc: 0.9572 - val_loss: 1.6672 - val_accuracy: 0.4876 - val_auc: 0.9526\n","Epoch 3/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 1.1751 - accuracy: 0.6360 - auc: 0.9714\n","Testing acc: 0.5821428298950195\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 1.1753 - accuracy: 0.6358 - auc: 0.9714 - val_loss: 1.3203 - val_accuracy: 0.6012 - val_auc: 0.9713\n","Epoch 4/100\n","1008/1008 [==============================] - ETA: 0s - loss: 1.0095 - accuracy: 0.6871 - auc: 0.9785\n","Testing acc: 0.6013888716697693\n","\n","1008/1008 [==============================] - 17s 16ms/step - loss: 1.0095 - accuracy: 0.6871 - auc: 0.9785 - val_loss: 1.2169 - val_accuracy: 0.6224 - val_auc: 0.9757\n","Epoch 5/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.8738 - accuracy: 0.7299 - auc: 0.9833\n","Testing acc: 0.5413690209388733\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.8737 - accuracy: 0.7298 - auc: 0.9833 - val_loss: 1.5097 - val_accuracy: 0.5433 - val_auc: 0.9623\n","Epoch 6/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.7762 - accuracy: 0.7606 - auc: 0.9862\n","Testing acc: 0.6752976179122925\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.7765 - accuracy: 0.7605 - auc: 0.9862 - val_loss: 1.0154 - val_accuracy: 0.6784 - val_auc: 0.9799\n","Epoch 7/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.6896 - accuracy: 0.7914 - auc: 0.9888\n","Testing acc: 0.5391865372657776\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.6895 - accuracy: 0.7915 - auc: 0.9888 - val_loss: 1.5454 - val_accuracy: 0.5636 - val_auc: 0.9587\n","Epoch 8/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.6072 - accuracy: 0.8184 - auc: 0.9907\n","Testing acc: 0.6266865134239197\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.6072 - accuracy: 0.8185 - auc: 0.9907 - val_loss: 1.1485 - val_accuracy: 0.6527 - val_auc: 0.9780\n","Epoch 9/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.5478 - accuracy: 0.8368 - auc: 0.9918\n","Testing acc: 0.6983134746551514\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.5477 - accuracy: 0.8368 - auc: 0.9918 - val_loss: 0.9775 - val_accuracy: 0.7189 - val_auc: 0.9776\n","Epoch 10/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.4954 - accuracy: 0.8535 - auc: 0.9928\n","Testing acc: 0.7317460179328918\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.4958 - accuracy: 0.8534 - auc: 0.9927 - val_loss: 0.7682 - val_accuracy: 0.7686 - val_auc: 0.9875\n","Epoch 11/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.4492 - accuracy: 0.8683 - auc: 0.9938\n","Testing acc: 0.6881944537162781\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.4493 - accuracy: 0.8682 - auc: 0.9938 - val_loss: 0.9281 - val_accuracy: 0.7135 - val_auc: 0.9847\n","Epoch 12/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.3963 - accuracy: 0.8847 - auc: 0.9951\n","Testing acc: 0.6917658448219299\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.3961 - accuracy: 0.8847 - auc: 0.9951 - val_loss: 0.9216 - val_accuracy: 0.7215 - val_auc: 0.9842\n","Epoch 13/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.8941 - auc: 0.9951\n","Testing acc: 0.620039701461792\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.3656 - accuracy: 0.8941 - auc: 0.9951 - val_loss: 1.1997 - val_accuracy: 0.6553 - val_auc: 0.9728\n","Epoch 14/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.3337 - accuracy: 0.9021 - auc: 0.9958\n","Testing acc: 0.6698412895202637\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.3336 - accuracy: 0.9021 - auc: 0.9958 - val_loss: 1.0275 - val_accuracy: 0.7024 - val_auc: 0.9789\n","Epoch 15/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.3193 - accuracy: 0.9063 - auc: 0.9962\n","Testing acc: 0.723809540271759\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.3191 - accuracy: 0.9064 - auc: 0.9962 - val_loss: 0.8235 - val_accuracy: 0.7576 - val_auc: 0.9867\n","Epoch 16/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.2734 - accuracy: 0.9192 - auc: 0.9969\n","Testing acc: 0.5797619223594666\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.2732 - accuracy: 0.9192 - auc: 0.9969 - val_loss: 1.4889 - val_accuracy: 0.6044 - val_auc: 0.9561\n","Epoch 17/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.2620 - accuracy: 0.9251 - auc: 0.9970\n","Testing acc: 0.7081349492073059\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.2619 - accuracy: 0.9251 - auc: 0.9970 - val_loss: 0.8528 - val_accuracy: 0.7476 - val_auc: 0.9801\n","Epoch 18/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.2321 - accuracy: 0.9323 - auc: 0.9974\n","Testing acc: 0.6456349492073059\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.2320 - accuracy: 0.9323 - auc: 0.9974 - val_loss: 1.1089 - val_accuracy: 0.6864 - val_auc: 0.9721\n","Epoch 19/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.2240 - accuracy: 0.9338 - auc: 0.9977\n","Testing acc: 0.5845237970352173\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.2239 - accuracy: 0.9338 - auc: 0.9977 - val_loss: 1.4035 - val_accuracy: 0.6042 - val_auc: 0.9589\n","Epoch 20/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.9374 - auc: 0.9979\n","Testing acc: 0.6708333492279053\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.2113 - accuracy: 0.9375 - auc: 0.9979 - val_loss: 1.0274 - val_accuracy: 0.7116 - val_auc: 0.9726\n","Epoch 21/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.1820 - accuracy: 0.9481 - auc: 0.9981\n","Testing acc: 0.7879960536956787\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.1820 - accuracy: 0.9481 - auc: 0.9981 - val_loss: 0.5603 - val_accuracy: 0.8368 - val_auc: 0.9892\n","Epoch 22/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9464 - auc: 0.9980\n","Testing acc: 0.502579391002655\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.1861 - accuracy: 0.9464 - auc: 0.9980 - val_loss: 1.7938 - val_accuracy: 0.5348 - val_auc: 0.9382\n","Epoch 23/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.9533 - auc: 0.9982\n","Testing acc: 0.7684524059295654\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.1671 - accuracy: 0.9533 - auc: 0.9982 - val_loss: 0.6918 - val_accuracy: 0.8095 - val_auc: 0.9803\n","Epoch 24/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.1600 - accuracy: 0.9532 - auc: 0.9983\n","Testing acc: 0.7650793790817261\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.1599 - accuracy: 0.9532 - auc: 0.9984 - val_loss: 0.6726 - val_accuracy: 0.8154 - val_auc: 0.9842\n","Epoch 25/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.1578 - accuracy: 0.9538 - auc: 0.9985\n","Testing acc: 0.7850198149681091\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.1580 - accuracy: 0.9538 - auc: 0.9985 - val_loss: 0.5857 - val_accuracy: 0.8347 - val_auc: 0.9849\n","Epoch 26/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.1501 - accuracy: 0.9566 - auc: 0.9984\n","Testing acc: 0.7397817373275757\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.1502 - accuracy: 0.9565 - auc: 0.9984 - val_loss: 0.7994 - val_accuracy: 0.7830 - val_auc: 0.9774\n","Epoch 27/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.1458 - accuracy: 0.9576 - auc: 0.9984\n","Testing acc: 0.7537698149681091\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.1460 - accuracy: 0.9576 - auc: 0.9984 - val_loss: 0.6953 - val_accuracy: 0.8022 - val_auc: 0.9834\n","Epoch 28/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.1216 - accuracy: 0.9652 - auc: 0.9989\n","Testing acc: 0.6498016119003296\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.1215 - accuracy: 0.9652 - auc: 0.9989 - val_loss: 1.1737 - val_accuracy: 0.6911 - val_auc: 0.9619\n","Epoch 29/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.1310 - accuracy: 0.9611 - auc: 0.9988\n","Testing acc: 0.7410714030265808\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.1309 - accuracy: 0.9612 - auc: 0.9988 - val_loss: 0.7584 - val_accuracy: 0.7943 - val_auc: 0.9759\n","Epoch 30/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.1227 - accuracy: 0.9631 - auc: 0.9988\n","Testing acc: 0.7512896656990051\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.1227 - accuracy: 0.9631 - auc: 0.9988 - val_loss: 0.7566 - val_accuracy: 0.8057 - val_auc: 0.9751\n","Epoch 31/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.1205 - accuracy: 0.9650 - auc: 0.9986\n","Testing acc: 0.779365062713623\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.1205 - accuracy: 0.9650 - auc: 0.9986 - val_loss: 0.6592 - val_accuracy: 0.8264 - val_auc: 0.9797\n","Epoch 32/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.1102 - accuracy: 0.9680 - auc: 0.9988\n","Testing acc: 0.7571428418159485\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.1104 - accuracy: 0.9679 - auc: 0.9988 - val_loss: 0.7075 - val_accuracy: 0.8105 - val_auc: 0.9789\n","Epoch 33/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9701 - auc: 0.9990\n","Testing acc: 0.658829391002655\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.1035 - accuracy: 0.9701 - auc: 0.9990 - val_loss: 1.1826 - val_accuracy: 0.7165 - val_auc: 0.9553\n","Epoch 34/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.1065 - accuracy: 0.9681 - auc: 0.9991\n","Testing acc: 0.6992063522338867\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.1066 - accuracy: 0.9681 - auc: 0.9991 - val_loss: 1.0341 - val_accuracy: 0.7414 - val_auc: 0.9624\n","Epoch 35/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.1029 - accuracy: 0.9695 - auc: 0.9991\n","Testing acc: 0.7070436477661133\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.1030 - accuracy: 0.9695 - auc: 0.9991 - val_loss: 0.9487 - val_accuracy: 0.7552 - val_auc: 0.9690\n","Epoch 36/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.9711 - auc: 0.9991\n","Testing acc: 0.6676587462425232\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0978 - accuracy: 0.9711 - auc: 0.9991 - val_loss: 1.1754 - val_accuracy: 0.7192 - val_auc: 0.9572\n","Epoch 37/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0912 - accuracy: 0.9730 - auc: 0.9992\n","Testing acc: 0.7669642567634583\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0912 - accuracy: 0.9730 - auc: 0.9992 - val_loss: 0.6782 - val_accuracy: 0.8139 - val_auc: 0.9794\n","Epoch 38/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0875 - accuracy: 0.9751 - auc: 0.9990\n","Testing acc: 0.8009920716285706\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0874 - accuracy: 0.9751 - auc: 0.9990 - val_loss: 0.5523 - val_accuracy: 0.8596 - val_auc: 0.9824\n","Epoch 39/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0916 - accuracy: 0.9735 - auc: 0.9992\n","Testing acc: 0.7009920477867126\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0916 - accuracy: 0.9735 - auc: 0.9992 - val_loss: 1.0833 - val_accuracy: 0.7494 - val_auc: 0.9581\n","Epoch 40/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0876 - accuracy: 0.9742 - auc: 0.9991\n","Testing acc: 0.8017857074737549\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0875 - accuracy: 0.9742 - auc: 0.9991 - val_loss: 0.6264 - val_accuracy: 0.8423 - val_auc: 0.9787\n","Epoch 41/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0763 - accuracy: 0.9786 - auc: 0.9993\n","Testing acc: 0.8028770089149475\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0763 - accuracy: 0.9785 - auc: 0.9993 - val_loss: 0.5425 - val_accuracy: 0.8580 - val_auc: 0.9838\n","Epoch 42/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9752 - auc: 0.9992\n","Testing acc: 0.8181547522544861\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0844 - accuracy: 0.9752 - auc: 0.9992 - val_loss: 0.5152 - val_accuracy: 0.8703 - val_auc: 0.9832\n","Epoch 43/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0774 - accuracy: 0.9775 - auc: 0.9993\n","Testing acc: 0.742559552192688\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0775 - accuracy: 0.9775 - auc: 0.9993 - val_loss: 0.8233 - val_accuracy: 0.7896 - val_auc: 0.9710\n","Epoch 44/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9782 - auc: 0.9993\n","Testing acc: 0.7740079164505005\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0716 - accuracy: 0.9782 - auc: 0.9993 - val_loss: 0.6943 - val_accuracy: 0.8299 - val_auc: 0.9755\n","Epoch 45/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9779 - auc: 0.9991\n","Testing acc: 0.7835317254066467\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0754 - accuracy: 0.9779 - auc: 0.9991 - val_loss: 0.6545 - val_accuracy: 0.8382 - val_auc: 0.9770\n","Epoch 46/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0732 - accuracy: 0.9783 - auc: 0.9992\n","Testing acc: 0.723115086555481\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0732 - accuracy: 0.9783 - auc: 0.9992 - val_loss: 0.9975 - val_accuracy: 0.7702 - val_auc: 0.9618\n","Epoch 47/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0702 - accuracy: 0.9794 - auc: 0.9993\n","Testing acc: 0.7950396537780762\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0701 - accuracy: 0.9794 - auc: 0.9993 - val_loss: 0.6235 - val_accuracy: 0.8497 - val_auc: 0.9779\n","Epoch 48/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9796 - auc: 0.9995\n","Testing acc: 0.7521825432777405\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0687 - accuracy: 0.9795 - auc: 0.9995 - val_loss: 0.7808 - val_accuracy: 0.8111 - val_auc: 0.9723\n","Epoch 49/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9801 - auc: 0.9994\n","Testing acc: 0.7561507821083069\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0665 - accuracy: 0.9800 - auc: 0.9994 - val_loss: 0.7780 - val_accuracy: 0.8186 - val_auc: 0.9710\n","Epoch 50/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9805 - auc: 0.9992\n","Testing acc: 0.7807539701461792\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0677 - accuracy: 0.9805 - auc: 0.9992 - val_loss: 0.6936 - val_accuracy: 0.8368 - val_auc: 0.9739\n","Epoch 51/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0605 - accuracy: 0.9816 - auc: 0.9995\n","Testing acc: 0.7590277791023254\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0605 - accuracy: 0.9816 - auc: 0.9995 - val_loss: 0.7916 - val_accuracy: 0.8134 - val_auc: 0.9706\n","Epoch 52/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9819 - auc: 0.9993\n","Testing acc: 0.8072420358657837\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0632 - accuracy: 0.9819 - auc: 0.9993 - val_loss: 0.5570 - val_accuracy: 0.8619 - val_auc: 0.9811\n","Epoch 53/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0605 - accuracy: 0.9826 - auc: 0.9993\n","Testing acc: 0.8000991940498352\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0604 - accuracy: 0.9827 - auc: 0.9993 - val_loss: 0.5254 - val_accuracy: 0.8540 - val_auc: 0.9855\n","Epoch 54/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9847 - auc: 0.9993\n","Testing acc: 0.8079364895820618\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0556 - accuracy: 0.9847 - auc: 0.9994 - val_loss: 0.5937 - val_accuracy: 0.8583 - val_auc: 0.9788\n","Epoch 55/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0586 - accuracy: 0.9823 - auc: 0.9994\n","Testing acc: 0.766865074634552\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0585 - accuracy: 0.9823 - auc: 0.9994 - val_loss: 0.7501 - val_accuracy: 0.8278 - val_auc: 0.9710\n","Epoch 56/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0551 - accuracy: 0.9840 - auc: 0.9995\n","Testing acc: 0.7996031641960144\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0551 - accuracy: 0.9839 - auc: 0.9995 - val_loss: 0.6338 - val_accuracy: 0.8465 - val_auc: 0.9761\n","Epoch 57/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9833 - auc: 0.9995\n","Testing acc: 0.8040674328804016\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0565 - accuracy: 0.9833 - auc: 0.9995 - val_loss: 0.5993 - val_accuracy: 0.8569 - val_auc: 0.9793\n","Epoch 58/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0489 - accuracy: 0.9856 - auc: 0.9997\n","Testing acc: 0.8131944537162781\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0488 - accuracy: 0.9856 - auc: 0.9997 - val_loss: 0.6287 - val_accuracy: 0.8588 - val_auc: 0.9755\n","Epoch 59/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0532 - accuracy: 0.9839 - auc: 0.9995\n","Testing acc: 0.7513889074325562\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0532 - accuracy: 0.9839 - auc: 0.9995 - val_loss: 0.8462 - val_accuracy: 0.7968 - val_auc: 0.9687\n","Epoch 60/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0495 - accuracy: 0.9850 - auc: 0.9996\n","Testing acc: 0.7740079164505005\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0495 - accuracy: 0.9851 - auc: 0.9996 - val_loss: 0.7593 - val_accuracy: 0.8229 - val_auc: 0.9723\n","Epoch 61/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9843 - auc: 0.9994\n","Testing acc: 0.7841269969940186\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0533 - accuracy: 0.9843 - auc: 0.9994 - val_loss: 0.7069 - val_accuracy: 0.8343 - val_auc: 0.9739\n","Epoch 62/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9856 - auc: 0.9997\n","Testing acc: 0.8085317611694336\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0460 - accuracy: 0.9856 - auc: 0.9997 - val_loss: 0.6164 - val_accuracy: 0.8602 - val_auc: 0.9756\n","Epoch 63/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9844 - auc: 0.9993\n","Testing acc: 0.8116071224212646\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0519 - accuracy: 0.9844 - auc: 0.9993 - val_loss: 0.5649 - val_accuracy: 0.8663 - val_auc: 0.9795\n","Epoch 64/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9875 - auc: 0.9995\n","Testing acc: 0.8057539463043213\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0437 - accuracy: 0.9875 - auc: 0.9995 - val_loss: 0.6558 - val_accuracy: 0.8456 - val_auc: 0.9747\n","Epoch 65/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9856 - auc: 0.9995\n","Testing acc: 0.8137896656990051\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0483 - accuracy: 0.9856 - auc: 0.9995 - val_loss: 0.5577 - val_accuracy: 0.8617 - val_auc: 0.9805\n","Epoch 66/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9861 - auc: 0.9996\n","Testing acc: 0.8105158805847168\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0473 - accuracy: 0.9862 - auc: 0.9996 - val_loss: 0.5905 - val_accuracy: 0.8574 - val_auc: 0.9794\n","Epoch 67/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9869 - auc: 0.9994\n","Testing acc: 0.7979166507720947\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0465 - accuracy: 0.9869 - auc: 0.9994 - val_loss: 0.6606 - val_accuracy: 0.8521 - val_auc: 0.9725\n","Epoch 68/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9879 - auc: 0.9997\n","Testing acc: 0.7966269850730896\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0411 - accuracy: 0.9879 - auc: 0.9997 - val_loss: 0.7128 - val_accuracy: 0.8500 - val_auc: 0.9706\n","Epoch 69/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9865 - auc: 0.9996\n","Testing acc: 0.8220238089561462\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0445 - accuracy: 0.9865 - auc: 0.9996 - val_loss: 0.5704 - val_accuracy: 0.8745 - val_auc: 0.9773\n","Epoch 70/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9884 - auc: 0.9997\n","Testing acc: 0.8114087581634521\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0417 - accuracy: 0.9884 - auc: 0.9997 - val_loss: 0.5935 - val_accuracy: 0.8661 - val_auc: 0.9765\n","Epoch 71/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9884 - auc: 0.9997\n","Testing acc: 0.7889881134033203\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0402 - accuracy: 0.9884 - auc: 0.9997 - val_loss: 0.7166 - val_accuracy: 0.8449 - val_auc: 0.9716\n","Epoch 72/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.9873 - auc: 0.9997\n","Testing acc: 0.8133928775787354\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0433 - accuracy: 0.9873 - auc: 0.9997 - val_loss: 0.5744 - val_accuracy: 0.8657 - val_auc: 0.9788\n","Epoch 73/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0467 - accuracy: 0.9859 - auc: 0.9996\n","Testing acc: 0.8092262148857117\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0467 - accuracy: 0.9859 - auc: 0.9996 - val_loss: 0.6313 - val_accuracy: 0.8574 - val_auc: 0.9751\n","Epoch 74/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9898 - auc: 0.9996\n","Testing acc: 0.8092262148857117\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0338 - accuracy: 0.9898 - auc: 0.9996 - val_loss: 0.6575 - val_accuracy: 0.8523 - val_auc: 0.9741\n","Epoch 75/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9880 - auc: 0.9997\n","Testing acc: 0.8101190328598022\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0391 - accuracy: 0.9880 - auc: 0.9997 - val_loss: 0.6624 - val_accuracy: 0.8557 - val_auc: 0.9738\n","Epoch 76/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9885 - auc: 0.9996\n","Testing acc: 0.810615062713623\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0388 - accuracy: 0.9885 - auc: 0.9997 - val_loss: 0.5746 - val_accuracy: 0.8630 - val_auc: 0.9791\n","Epoch 77/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9894 - auc: 0.9996\n","Testing acc: 0.8032737970352173\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0374 - accuracy: 0.9894 - auc: 0.9996 - val_loss: 0.6392 - val_accuracy: 0.8535 - val_auc: 0.9760\n","Epoch 78/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9885 - auc: 0.9997\n","Testing acc: 0.8062499761581421\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0369 - accuracy: 0.9885 - auc: 0.9997 - val_loss: 0.6328 - val_accuracy: 0.8555 - val_auc: 0.9755\n","Epoch 79/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.9897 - auc: 0.9997\n","Testing acc: 0.8023809790611267\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0348 - accuracy: 0.9898 - auc: 0.9997 - val_loss: 0.6632 - val_accuracy: 0.8540 - val_auc: 0.9729\n","Epoch 80/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9905 - auc: 0.9998\n","Testing acc: 0.7944444417953491\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0316 - accuracy: 0.9904 - auc: 0.9998 - val_loss: 0.7564 - val_accuracy: 0.8470 - val_auc: 0.9682\n","Epoch 81/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9903 - auc: 0.9997\n","Testing acc: 0.7904762029647827\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0345 - accuracy: 0.9903 - auc: 0.9997 - val_loss: 0.7317 - val_accuracy: 0.8398 - val_auc: 0.9716\n","Epoch 82/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9896 - auc: 0.9996\n","Testing acc: 0.824999988079071\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0367 - accuracy: 0.9896 - auc: 0.9996 - val_loss: 0.5664 - val_accuracy: 0.8730 - val_auc: 0.9774\n","Epoch 83/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9900 - auc: 0.9997\n","Testing acc: 0.8227182626724243\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0331 - accuracy: 0.9900 - auc: 0.9997 - val_loss: 0.5623 - val_accuracy: 0.8759 - val_auc: 0.9775\n","Epoch 84/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9909 - auc: 0.9997\n","Testing acc: 0.8286706209182739\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0310 - accuracy: 0.9909 - auc: 0.9997 - val_loss: 0.5859 - val_accuracy: 0.8749 - val_auc: 0.9761\n","Epoch 85/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9901 - auc: 0.9998\n","Testing acc: 0.8261904716491699\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0342 - accuracy: 0.9900 - auc: 0.9998 - val_loss: 0.5666 - val_accuracy: 0.8702 - val_auc: 0.9780\n","Epoch 86/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9903 - auc: 0.9995\n","Testing acc: 0.8172619342803955\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0346 - accuracy: 0.9903 - auc: 0.9995 - val_loss: 0.6072 - val_accuracy: 0.8699 - val_auc: 0.9762\n","Epoch 87/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9909 - auc: 0.9997\n","Testing acc: 0.8122023940086365\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0327 - accuracy: 0.9908 - auc: 0.9997 - val_loss: 0.6086 - val_accuracy: 0.8642 - val_auc: 0.9768\n","Epoch 88/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9913 - auc: 0.9997\n","Testing acc: 0.8096230030059814\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0311 - accuracy: 0.9913 - auc: 0.9997 - val_loss: 0.6883 - val_accuracy: 0.8609 - val_auc: 0.9712\n","Epoch 89/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9903 - auc: 0.9997\n","Testing acc: 0.8097222447395325\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0303 - accuracy: 0.9904 - auc: 0.9997 - val_loss: 0.6729 - val_accuracy: 0.8599 - val_auc: 0.9721\n","Epoch 90/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9908 - auc: 0.9997\n","Testing acc: 0.8202381134033203\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0314 - accuracy: 0.9908 - auc: 0.9997 - val_loss: 0.6332 - val_accuracy: 0.8630 - val_auc: 0.9748\n","Epoch 91/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9916 - auc: 0.9997\n","Testing acc: 0.8129960298538208\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0280 - accuracy: 0.9916 - auc: 0.9997 - val_loss: 0.6396 - val_accuracy: 0.8679 - val_auc: 0.9731\n","Epoch 92/100\n","1007/1008 [============================>.] - ETA: 0s - loss: 0.0304 - accuracy: 0.9907 - auc: 0.9997\n","Testing acc: 0.8082341551780701\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0306 - accuracy: 0.9906 - auc: 0.9997 - val_loss: 0.6550 - val_accuracy: 0.8579 - val_auc: 0.9730\n","Epoch 93/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9914 - auc: 0.9997\n","Testing acc: 0.8223214149475098\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0306 - accuracy: 0.9914 - auc: 0.9997 - val_loss: 0.5989 - val_accuracy: 0.8736 - val_auc: 0.9755\n","Epoch 94/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9912 - auc: 0.9997\n","Testing acc: 0.8122023940086365\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0305 - accuracy: 0.9912 - auc: 0.9997 - val_loss: 0.6219 - val_accuracy: 0.8679 - val_auc: 0.9752\n","Epoch 95/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9921 - auc: 0.9997\n","Testing acc: 0.8185515999794006\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0277 - accuracy: 0.9921 - auc: 0.9997 - val_loss: 0.6343 - val_accuracy: 0.8672 - val_auc: 0.9740\n","Epoch 96/100\n","1008/1008 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9912 - auc: 0.9997\n","Testing acc: 0.8221229910850525\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0288 - accuracy: 0.9912 - auc: 0.9997 - val_loss: 0.6781 - val_accuracy: 0.8669 - val_auc: 0.9711\n","Epoch 97/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9926 - auc: 0.9996\n","Testing acc: 0.8103174567222595\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0273 - accuracy: 0.9926 - auc: 0.9996 - val_loss: 0.6660 - val_accuracy: 0.8609 - val_auc: 0.9722\n","Epoch 98/100\n","1006/1008 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9918 - auc: 0.9998\n","Testing acc: 0.8137896656990051\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0273 - accuracy: 0.9918 - auc: 0.9998 - val_loss: 0.6792 - val_accuracy: 0.8578 - val_auc: 0.9714\n","Epoch 99/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9934 - auc: 0.9997\n","Testing acc: 0.805654764175415\n","\n","1008/1008 [==============================] - 17s 17ms/step - loss: 0.0238 - accuracy: 0.9934 - auc: 0.9997 - val_loss: 0.6690 - val_accuracy: 0.8611 - val_auc: 0.9723\n","Epoch 100/100\n","1005/1008 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.9909 - auc: 0.9996\n","Testing acc: 0.8101190328598022\n","\n","1008/1008 [==============================] - 18s 18ms/step - loss: 0.0305 - accuracy: 0.9909 - auc: 0.9996 - val_loss: 0.6347 - val_accuracy: 0.8628 - val_auc: 0.9752\n"]}]},{"cell_type":"code","source":["results[1]*100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2aThm8UbcZFH","executionInfo":{"status":"ok","timestamp":1659209897953,"user_tz":-120,"elapsed":311,"user":{"displayName":"Modafar Al-Shouha","userId":"08841682443665180805"}},"outputId":"fe3f8a24-d19e-4533-d732-876623069902"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["81.01190328598022"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["test_preds = model.predict(X_test)"],"metadata":{"id":"WfdhMlm9ndP9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_preds.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NVcJzM5gnm3Z","executionInfo":{"status":"ok","timestamp":1659209946269,"user_tz":-120,"elapsed":299,"user":{"displayName":"Modafar Al-Shouha","userId":"08841682443665180805"}},"outputId":"eddb233d-15c1-4541-f94c-22e44a897e45"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10080, 28)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["data_file = '/content/drive/MyDrive/PhD/Szeged22_paper/Atca_Cyber_long_paper/data/arabic_alex_preds.npz'\n","np.savez_compressed(data_file, arab_preds=test_preds)"],"metadata":{"id":"y19cuJE2ntss"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Balanced accuracy"],"metadata":{"id":"SuJVESDHJ8_f"}},{"cell_type":"code","source":["model = keras.models.load_model('/content/drive/MyDrive/PhD/Szeged22_paper/Atca_Cyber_long_paper/saved_models/alexNet_classifier.h5')"],"metadata":{"id":"nIBSfFjkPE2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = model.predict(X_test)"],"metadata":{"id":"-i2KjvspKCKc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sklearn.metrics.balanced_accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(y_pred, axis=-1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zzXiXmeIKknE","executionInfo":{"status":"ok","timestamp":1659370556655,"user_tz":-120,"elapsed":20,"user":{"displayName":"Modafar Al-Shouha","userId":"08841682443665180805"}},"outputId":"61f72cc5-0e7f-4508-e37f-ef1a9bf41203"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8101190476190476"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[""],"metadata":{"id":"5VeG_K2WoN9f"},"execution_count":null,"outputs":[]}]}